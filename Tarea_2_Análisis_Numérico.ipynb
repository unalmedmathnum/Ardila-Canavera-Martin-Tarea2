{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/macaluzate/Ardila-Canavera-Martin/blob/main/Tarea_2_An%C3%A1lisis_Num%C3%A9rico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ğŸ˜€PORTADAğŸ˜€**"
      ],
      "metadata": {
        "id": "25Y3spuLPLhZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "  \n",
        "\n",
        "## **ğŸ“‰ğŸ“ˆâ•âœ–ï¸â–â—ğŸŸ°ğŸ“šğŸ“™âœï¸ğŸ–‹ï¸âœ’ï¸ğŸ“ğŸ“‰ğŸ“ˆâ•âœ–ï¸â–â—ğŸŸ°ğŸ“šğŸ“™âœï¸ğŸ–‹ï¸âœ’ï¸ğŸ“ğŸ“‰ğŸ“ˆâ•âœ–ï¸**\n",
        "\n",
        "## **MÃ¨todo de MÃ¬nimos Cuadrados**\n",
        "\n",
        "## **Asignatura**\n",
        "\n",
        "  AnÃ lisis NumÃ¨rico\n",
        "\n",
        "## **Profesor**\n",
        "  Manuela Bastidas Olivares\n",
        "\n",
        "## **Estudiantes**\n",
        " Maria Paula Ardila Otero\n",
        "\n",
        " Mateo CaÃ±avera Aluma\n",
        "\n",
        " David Esteban Martin Acosta\n",
        "\n",
        "\n",
        "## **Universidad Nacional de Colombia**\n",
        "## **Sede MedellÃ­n**\n",
        "## **2024 - 2**\n",
        "\n",
        "## **ğŸ“‰ğŸ“ˆâ•âœ–ï¸â–â—ğŸŸ°ğŸ“šğŸ“™âœï¸ğŸ–‹ï¸âœ’ï¸ğŸ“ğŸ“‰ğŸ“ˆâ•âœ–ï¸â–â—ğŸŸ°ğŸ“šğŸ“™âœï¸ğŸ–‹ï¸âœ’ï¸ğŸ“ğŸ“‰ğŸ“ˆâ•âœ–ï¸**\n",
        "\n",
        "\n",
        "</center>"
      ],
      "metadata": {
        "id": "AsUYczPcPNGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ğŸ§ TeorÃ­a de los MÃ­nimos CuadradosğŸ§ **"
      ],
      "metadata": {
        "id": "FYPtCID-5cNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"justify\">\n",
        "\n",
        "**ğŸ—ï¸SubespaciosğŸ—ï¸**\n",
        "\n",
        "Trabajamos sobre el espacio vectorial $V = \\mathbb{R}^n $. Comenzamos con el concepto de subespacio lineal.\n",
        "\n",
        "**DEFINICIÃ“N (Subespacio lineal)** Un subespacio lineal de $\\mathbb{R}^n$ es un subconjunto $ U \\subseteq \\mathbb{R}^n$ que estÃ¡ cerrado bajo la suma de vectores y la multiplicaciÃ³n por escalares. Es decir, para todo $u_1, u_2 \\in U $ y $\\alpha \\in \\mathbb{R}$, se cumple que:\n",
        "\n",
        "$$u_1 + u_2 \\in U \\quad \\text{y} \\quad \\alpha u_1 \\in U.$$\n",
        "\n",
        "Se sigue de esta condiciÃ³n que \\$ 0 \\in U$.\n",
        "\n",
        "Alternativamente, podemos verificar estas condiciones demostrando que:\n",
        "\n",
        "- (1) $ 0 \\in U$\n",
        "- (2) $u_1, u_2 \\in U$\n",
        "\n",
        "$\\alpha \\in \\mathbb{R}$ implican que $\\alpha u_1 + u_2 \\in U$. De hecho, al tomar $\\alpha = 1$ se cumple la primera condiciÃ³n anterior, mientras que al elegir $u_2 = 0$ se obtiene la segunda.\n",
        "\n",
        "\n",
        "**Ejemplo**: El plano $P$ formado por todos los puntos $(x, y, z) \\in \\mathbb{R}^3$ que satisfacen $z = x + y$ es un subespacio lineal. De hecho, $0 = 0 + 0$ por lo que $(0, 0, 0) \\in P$. Y, para cualquier $u_1 = (x_1, y_1, z_1)$y $u_2 = (x_2, y_2, z_2)$ tales que $z_1 = x_1 + y_1$ y $z_2 = x_2 + y_2$ y para cualquier $\\alpha \\in \\mathbb{R}$, tenemos que:\n",
        "\n",
        "$$\n",
        "\\alpha z_1 + z_2 = \\alpha(x_1 + y_1) + (x_2 + y_2) = (\\alpha x_1 + x_2) + (\\alpha y_1 + y_2).\n",
        "$$\n",
        "\n",
        "Es decir, $\\alpha u_1 + u_2$ satisface la condiciÃ³n que define a $P$ y por lo tanto, estÃ¡ en $P$. Nota tambiÃ©n que $P$ pasa por el origen.\n",
        "\n",
        "En este ejemplo, el subespacio lineal $P$ puede describirse alternativamente como la colecciÃ³n de cada vector de la forma $(x, y, x + y)$.\n",
        "\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "7V7X8pbJ6M28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MGyYALeZ5aqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ğŸ§ AnÃ lisis de resultadosğŸ’¡**"
      ],
      "metadata": {
        "id": "9xAcsCwjQJYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"justify\">\n",
        "\n",
        "**InterpretaciÃ²n de los resultados del modelo de MÃ­nimos Cuadrados**\n",
        "\n",
        "El modelo de MÃ­nimos Cuadrados utilizado en este proyecto tiene como objetivo minimizar la diferencia cuadrada entre las representaciones de firmas autÃ©nticas, extrayendo caracterÃ­sticas discriminativas entre las firmas comparadas. Al calcular la **diferencia cuadrada** entre las representaciones de las dos firmas de entrada $(output1$ y $output2)$, la funciÃ³n de pÃ©rdida, $ContrastiveLoss$, penaliza las diferencias grandes entre firmas genuinas mientras que no afecta las diferencias cuando las firmas son forjadas. Esta estrategia estÃ¡ diseÃ±ada para fomentar la compactaciÃ³n de las representaciones de firmas genuinas y aumentar la distancia entre las representaciones de firmas forjadas.\n",
        "\n",
        "**El objetivo final del modelo es que, para las parejas de firmas genuinas (etiquetadas con 1), la distancia cuadrada entre las representaciones sea lo mÃ¡s pequeÃ±a posible, mientras que para las parejas de firmas falsas (etiquetadas con 0), la distancia no deberÃ­a contribuir al error**.\n",
        "\n",
        "**âš ï¸Los resultados del modelo pueden interpretarse en tÃ©rminos de la reducciÃ³n en el valor de la pÃ©rdida a lo largo de las iteraciones de entrenamiento, lo cual indica que el modelo estÃ¡ aprendiendo a distinguir correctamente entre firmas genuinas y falsificadas.âš ï¸**\n",
        "\n",
        "La implementaciÃ³n de mÃ­nimos cuadrados muestra caracterÃ­sticas importantes:\n",
        "\n",
        "1. **Sensibilidad a Variaciones:**\n",
        "\n",
        "    - Captura efectivamente diferentes grados de similitud\n",
        "    - Proporciona una mÃ©trica continua de similitud\n",
        "    - Mantiene consistencia en las predicciones\n",
        "\n",
        "2. **Escala de Distancias:**\n",
        "\n",
        "    - Rango de valores interpretable (0 a 1)\n",
        "    - CorrelaciÃ³n clara entre distancia y similitud\n",
        "    - Umbral natural para clasificaciÃ³n\n",
        "</div>"
      ],
      "metadata": {
        "id": "5GCR_rmgQaiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>"
      ],
      "metadata": {
        "id": "ycF03gJ1Uy9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"justify\">\n",
        "\n",
        "**Discutir la calidad del ajuste y las limitaciones del mÃ©todo en tu aplicaciÃ³n especÃ­fica**\n",
        "\n",
        "La calidad del ajuste de este modelo depende de varios factores. El mÃ©todo de MÃ­nimos Cuadrados es eficaz en escenarios donde las relaciones entre las caracterÃ­sticas de las firmas se pueden modelar de manera lineal o donde las diferencias entre clases (genuinas vs. falsas) no son extremadamente complejas. Sin embargo, hay varios aspectos a considerar:\n",
        "\n",
        "- **Calidad del ajuste:** Si el modelo ha sido entrenado adecuadamente y el valor de la pÃ©rdida se ha reducido significativamente a lo largo del entrenamiento, podemos suponer que el modelo estÃ¡ aprendiendo una buena representaciÃ³n de las firmas. Un valor bajo de la pÃ©rdida generalmente indica que el modelo estÃ¡ ajustando bien las representaciones. Sin embargo, este ajuste puede no ser perfecto si los datos de entrada tienen ruidos o inconsistencias, como firmas mal escaneadas o variaciones extremas en la escritura.\n",
        "\n",
        "- **Limitaciones:** A pesar de sus ventajas, el mÃ©todo de MÃ­nimos Cuadrados presenta algunas limitaciones. En aplicaciones de verificaciÃ³n de firmas manuscritas, las variaciones naturales en la forma de firmar pueden generar errores en la comparaciÃ³n. Este modelo no captura de manera eficiente las complejidades de las firmas en ciertos casos, como las firmas que han sido realizadas bajo diferentes condiciones fÃ­sicas o emocionales. AdemÃ¡s, el mÃ©todo no tiene en cuenta las posibles transformaciones geomÃ©tricas (como rotaciÃ³n o escala) que pueden ocurrir en las imÃ¡genes de las firmas.\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "NdBldGsGU0ML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>"
      ],
      "metadata": {
        "id": "GajViQxtXECp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"justify\">\n",
        "\n",
        "**Sugerencia de posibles mejoras y enfoques alternativos**\n",
        "\n",
        "Si bien el uso de MÃ­nimos Cuadrados para la verificaciÃ³n de firmas ofrece una aproximaciÃ³n sÃ³lida, se pueden considerar varias mejoras y enfoques alternativos:\n",
        "\n",
        "- **Aumento de datos:** A medida que los modelos de redes neuronales se entrenan con mÃ¡s variabilidad en los datos, el ajuste y la robustez mejoran significativamente. TÃ©cnicas como la rotaciÃ³n, la distorsiÃ³n y el cambio de escala pueden generar mÃ¡s datos de entrenamiento para manejar mejor las variaciones en las firmas.\n",
        "\n",
        "- **Redes neuronales profundas (Deep Learning):** Aunque las redes siamesas ofrecen una estructura efectiva para comparar pares de firmas, el uso de modelos mÃ¡s complejos como redes neuronales convolucionales (CNN) o arquitecturas de redes neuronales recurrentes (RNN) podrÃ­a mejorar la extracciÃ³n de caracterÃ­sticas, especialmente para firmas con alta variabilidad o estilos de escritura complejos.\n",
        "\n",
        "- **TÃ©cnicas de RegularizaciÃ³n:** Para evitar el sobreajuste (overfitting), que puede ocurrir cuando el modelo es entrenado en un conjunto de datos limitado, se pueden incorporar tÃ©cnicas de regularizaciÃ³n como Dropout, L2 regularization o Data Augmentation.\n",
        "\n",
        "\n",
        "- **Enfoques alternativos:** En lugar de usar MÃ­nimos Cuadrados, se podrÃ­an explorar otras funciones de pÃ©rdida, como la pÃ©rdida de contraste o la pÃ©rdida de tripletas, que podrÃ­an ser mÃ¡s adecuadas para la comparaciÃ³n de firmas, especialmente cuando se busca una mayor distancia entre las firmas genuinas y falsas.\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "GnKcOE_VXFG-"
      }
    }
  ]
}